[EKS 기반 개발 가이드]

1.Cluster 구성 가이드
1.1.EKS 사용을 위한 사전 작업
    - EKS 클러스터를 생성하기 전에 Kubernetes가 AWS 리소스 생성시 사용하는 IAM 계정 및 Role과 클러스터가 사용할 VPC를 생성해야 합니다
    
      1)Amazon IAM 계정 생성
      2)Amazon EKS 서비스 Role 생성
      3)Amazon EKS 클러스터 VPC 생성
      4)EKS workspace 생성 및 IAM Role 연결
      5)Kubernetes 설치하기 
      6)Helm 설치하기

1.2.EKS Cluster 생성하기
    1)eksctl binary file 다운로드
    2)EKS 클러스터 생성
    3)EKS 클러스터 Node 정보 확인

1.3.Kubernetes Dashboard 구성하기
    - Kubernetes dashboard를 생성하고 접속 방법을 설명합니다

1.4.Autoscaling Applications and Clusters
    - 사용율에 따라 자동으로 어플리케이션(HPA:Horizontal Pod Autoscaler)과 호스트 클러스터(CA:Cluster Autoscaler)를 autoscaling 하는 방법을 설명합니다
    
    1)Auto scaling the applications configuration
      - 클러스터의 자원 사용율 데이터를 수집할 Metric 서버를 설치 
    2)Application autoscaling test
      - deploy한 web application에 부하를 줄 road-generator를 실행하고 해당 web service에 반복적으로 접속을 수행합니다.
    3)Auto scaling the clusters configuration
      - workspace에 Cluster Autoscaler를 위한 yaml 파일을 다운로드 받습니다
    4)Cluster node autoscaling test
      - 테스트용 web application을 실행

2.Container Registry 사용방법
2-1.Amazon ECR 소개
    - Amazon Elastic Container Registry(ECR)은 완전 관리형 AWS 도커 컨테이너 레지스트리 서비스이다. 
    - 해당 서비스를 이용하여 Docker CLI을 이용해 이미지를 관리할 수 있다. 
    - 개발자는 Docker 컨테이너 이미지를 저장, 관리할 수 있으며, IAM과 결합하여 각 Repository에 대한 리소스 관리가 가능하다. 

2-2.사용 방법
    - Amazon ECR 서비스를 이용하기 위해 아래와 같이 Repository를 생성할 수 있다. 
    - 생성된 Repository를 이용해 EKS에서 Docker 서비스를 사용할 수 있다. 
    - EKS에 생성한 Repository > 상세 화면에서 푸시알람보기 버튼을 클릭하면 Docker 명령어를 위한 정보가 확인된다. 
    - 명령어를 이용해 서비스 인증 후 Docker Service를 사용할 수 있다. 

2-3.고려사항
    - 일반적으로 제공되는 Private Docker Registry의 경우 하나의 프로젝트가 사용할 Private Registry를 생성한 후 안에 각 개발자가 환경에 맞춰 Image Repository 이름을 정의해서 Image Tag (<Name>:<tag>) 생성 후 Push 하는 방식으로 사용된다. 
    - 하여, CLI를 이용해 사용할 시점에 알맞은 Image Repository 이름을 정의한 후 사용할 수 있다. 
    - 이에 반해, ECR은 Amazon 콘솔 화면을 통해 Image Repository 이름을 먼저 생성 한 후 정의된 이름을 이용해 Image Tag 생성 후 Push를 진행해야 한다. 
    - 권한이 있는 사용자가 명시적으로 Image Repository의 이름을 정의한 이후에 Registry를 사용할 수 있기 때문에 다수의 개발자가 사용하는 Private Registry로는 사용이 불편할 수 있다. 

2-4.가격 정책
    - Amazon ECR은 저장한 데이터와 인터넷으로 전송한 데이터 양에 대해 요금을 지불한다. 
    - 데이터 저장은 월별 GB당 0.10 USD이며, 1년동안 매월 500MB의 스토리지를 무료로 사용할 수 있다. 추가로 데이터 송신 비용이 청구된다. 

3.CodePipeline을 활용한 CI/CD 구성하기
3-1.Amazon CodePipeline 소개
    - AWS CodePipeline은 빠르고 안정적인 애플리케이션 및 인프라 업데이트를 위해 릴리스 파이프라인을 자동화하는 데 도움이 되는 완전관리형 지속적 전달 서비스이다.
    - CodePipeline은 코드 변경이 발생할 때마다 사용자가 정의한 릴리스 모델을 기반으로 릴리스 프로세스의 빌드, 테스트 및 배포 단계를 자동화한다. 따라서 기능과 업데이트를 신속하고 안정적으로 제공할 수 있다.
    - AWS CodePipeline을 GitHub 또는 자체 사용자 지정 플러그인과 같은 타사 서비스와 손쉽게 통합할 수 있다. 
    - AWS CodePipeline는 AWS 서비스를 이용해 소스관리는 CodeCommit, 빌드는 CodeBuild, 배포는 CodeDeploy 서비스와 결합하여 사용할 수 있다. 
    - AWS EKS는 현재 CodeCommit, CodeBuild와 함께하여 Pipeline을 구성할 수 있다

3-2.사용 방법
    - AWS EKS용 Pipeline을 구성하는 방법에 대해 설명한다. 
    - 해당 예제는 Git과 연동하여  Pipeline을 구성하며 CodeBuild를 통해 소스가 빌드되는 부분까지 확인할 수 있다. 
    - 테스트를 위해 CloudFormation을 이용해 스택을 생성한다
    - 파이프라인 구성 스택 URL : https://s3.amazonaws.com/eksworkshop.com/templates/master/ci-cd-codepipeline.cfn.yml?stackName=eksws-codepipeline
    - Git 연동을 위해 Github Username과 Access token을 입력해준다
    - 스택 구성이 완료된 후 CodePipeline에 접속하면 정상적으로 소스가 Git에서 다운로드 되어 빌드된 것을 확인할 수 있다. 
    - 또한, Git에 배포된 소스를 변경하면 자동으로 반영되어 재빌드가 되는 것을 확인할 수 있다

3-3.가격 정책
    - Amazon CodePipeline은 사용량에 따라 가격이 측정된다. 
    - 사용 기간이 30일 이상이며, 1개월간 코드가 1회 이상 변경된 파이프라인을 월별 활성 파이프라인이라고 하는데, 
    - 비용은 월별 활성 파이프라인 * 1 USD이다.  
    - CodePipeline과 함께 S3와 같은 다른  서비스를 결합하여 사용하는 경우 기타 서비스에 대한 가격은 모두 각각 측정되어 청구된다

4.로그 분석 및 모니터링 방법
4-1.Kubernetes Dashboard를 활용한 모니터링
    - 현재 AWS Cloudwatch를 이용하여 EKS 서비스에 대한 모니터링은 일부 항목을 제외하고는 되지 않으므로 Kubernetes native dashboard을 설치하여 Kubernetes 항목에 대해 모니터링 하는 것을 권장한다. 
    - Kubernetes native dashboard를 설치하여 사용하는 방법은 EKS 4. 로그 분석 및 모니터링 방법 페이지에서 확인할 수 있다. 

4-2.EFK 서비스를 활용한 모니터링
    - EC2 및 Application(Pod)로그는 EFK (Fluentd daemonset -> ElasticSearch -> Kibana)가 Kubernetes  환경에서의 가장 권장되는 구성이다.
    - AWS의 관리형 ElasticSearch 서비스인 AmazonES (Kibana 기본 탑재)를 활용하실 수 있고 Amazon S3로 각 Pod의 로그를 저장하여 AWS의 다양한 데이터 분석 서비스를 통해 분석 및 시각화가 가능하다. 
    - EFK를 구성하기 위해 ElasticSearch를 Provison 해주는 작업을 우선 진행해야 한다. 
    - 작업이 완료되면 AWS ElasticSearch 대시보드에서 아래와 같이 kubernetes-logs이 생성된 것을 확인할 수 있다. 
    - ElasticSearch 작업이 완료되면, Fluentd를 Deploy 한다.
    - FluentD 배포가 완료되면, AWS CloudWatch 콘솔 화면에서 아래와 같이 로그 그룹이 생성된 것을 확인할 수 있다. 
    - 로그 그룹 생성이 되면, Lambda를 생성하여 ElasticSearch와 연동할 수 있게 해준다. 
    - AWS CloudWatch 콘솔 화면에서 로그 그룹을 선택 한 후 수집된 로그가 Amazon ElasticSearch로 전달될 수 있도록 설정해준다
    - 설정이 완료되면, AWS ElasticSearch 콘솔에 들어가면, Kibana URL을 확인할 수 있고, 해당 URL로 접속하면 Kibana에 수집된 로그를 확인할 수 있다


[EKS 아키텍처 가이드]
1.아키텍처 구성 및 고려사항
1-1.EKS 개요
    - EKS(Amazon Elastic Container Service for Kubernetes)는 Kubernetes를 사용하여 컨테이너식 애플리케이션을 손쉽게 배포, 관리 및 확장할 수 있게 해주는 서비스이다. 
    - EKS는 Kubernetes 커뮤니티의 기존 도구 및 플러그인을 사용할 수 있으며, 
    - ECS, ECR, Pipeline 등 Amazon에서 제공하는 각종 서비스와 결합하여 사용도 가능하다
    
1-2.아키텍처 구성 
    - AWS Container Service의 전체적인 아키텍쳐이다. 
    - Control Plane은 컨테이너 클러스터 마스터 역할을 수행하는 곳으로 Amazon ECS, EKS가 있다. 
    - DataPlane은 실제로 컨테이너들이 배포되는 곳으로 AWS Fargate, EC2가 있다.  
    - 이외에 AWS CodePipeline을 이용해 CI/CD 파이프라인 구성이 가능하며, 
    - Registry로 Amazon ECR을 사용하는 것이 가능하다. 
    - 또한, RDS, S3, EFS 서비스와의 결합도 가능하다

1-3.EKS vs ECS vs Elastic Beanstalk vs Fargate 비교
    - 컨테이너를 실행할 수 있는 다양한 서비스가 존재하며, 
    - 기능 비교를 통해 각자의 환경에 적합한 서비스를 활용할 수 있도록 한다
    
  1)EKS(Elastic Container Service for Kubernetes)
    - Kubernetes를 사용하는 컨테이너식 어플리케이션 관리형 환경이다. 
    - Amazon EKS는 Kubernetes Master를 여러 가용 영역(Availability Zone)에 자동으로 배포함으로 가용성이 높은 아키텍처를 제공하는 클라우드 서비스이다. 
    - EKS에서 실행되는 Application은 단일 마스터 혹은 전체 가용 영역의 손실에 대해 복원력을 가지며 마스터에 대한 위험 요소 탐지, 버전 업그레이드를 자동으로 수행한다. 
    - 클러스터의 관리, 확장 및 업그레이드와 관련된 작업을 자동화. 
    - AWS의 모든 성능, 확장성, 안정성 및 가용성
    - 애플리케이션 로드 밸런서
    - AWS IAM(Identity and Access Management)
    - AWS 프라이빗 링크(PrivateLink)
    - AWS 클라우드 트레일(CloudTrail)
    - AWS 네트워킹 및 보안 서비스 

  2)ECS(Elastic Container Service)
    - 클러스터에서 Docker 컨테이너를 쉽게 실행, 중지, 관리 해주는 컨테이너 관리 서비스. 
    - AWS에서 컨테이너식 어플리케이션을 쉽게 실행하고 확장, 축소할 수 있으며 시작유형으로 Fargate, EC2를 선택할 수 있다. 
    - 간단한 API 호출을 사용하여 컨테이너 기반 어플리케이션을 시작, 중지할 수 있고 중앙 집중식 서비스를 사용하여 클러스터 상태를 확인할 수 있도록 해준다. 
    - 사용자가 자체 클러스터 관리 및 구성 관리 시스템을 운영하거나 인프라 조정을 신경 쓸 필요 없이 일관된 배포 및 구축 환경을 생성하고, MSA 모델에 정교한 어플리케이션 아키텍처를 구축할 수 있다. 

  3)Elastic Beanstalk
    - AWS 환경에서 가장 쉽게 웹 어플리케이션 / 웹 서비스를 배포하고, 확장하고, 관리할 수 있는 완전 관리형 서비스.  
    - Java, .NET, PHP, Node.js, Python, Ruby, Go, Docker를 사용.
    - Apache, Nginx, Passenger, IIS와 같은 친숙한 서버에서 개발된 웹 애플리케이션 및 서비스를 간편하게 배포하고 조정할 수 있다. 
    - 어플리케이션을 업로드만 하면 용량 프로비저닝, 부하분산, 조정, 모니터링, 배포 등을 자동으로 처리해주어 개발자가 어플리케이션을 실행하는데 필요한 인프라에 대한 고민 없이 AWS 클라우드에서 어플리케이션을 신속하게 배포하고 관리할 수 있게 한다.

1-4.Kubernetes와 EKS 비교
    - 관리형 Kubernetes 제어 플레인 : 높은 가용성을 보장하기 위해 3개 가용 영역에서 Kubernetes 제어 플레인을 실행하고 비정상 Master를 자동으로 감지해서 교체함
    - 각 클러스터의 etcd와 API 서버의 가용성과 확장성을 자동으로 관리함
    - AWS IAM의 상세한 정책 관리 : IAM과 Heptio를 이용해 Kubenretes 마스터에 대한 액세스 권한을 세분화 하여 제어할 수 있음
    - VPC 지원 : EKS는 AWS의 VPC 내의 워커 노드에 배포되므로 VPC의 기능(Route Table, Nat G/W, Security Group, NACL 등)을 사용하여 높은 수준의 보안 설정이 가능함
    - 네트워킹 정책 : Calico와 연동하여 Kubernetes 워크로드에 대한 세분화된 네트워킹 정책을 제공함
    - 로깅 및 모니터링 : AWS Cloudtrail을 사용하여 EKS API에 대한 호출 내역을 확인할 수 있으며, AWS Cloudwatch, ElasticSearch를 사용하여 애플리케이션의 상태 확인이 가능함
    - Private Container Registry : Amazon Elastic Container Registry와 결합하여 손쉽게 Private Docker 이미지를 저장하고 액세스가 가능함
    - 빌드 구성 : AWS Codepipeline를 사용하여 인증을 설정할 필요 없이 Kubernetes Engine에서 안정적으로 컨테이너 배포가 가능함


2.플랫폼 테스트 결과
2-1.테스트 결과 요약
    - Amazon Web Services에서 서비스중인 EKS(Elastic Container Service for Kubernetes)의 플랫폼 기능을 사용해보고 테스트한 결과,
    - AWS ECS(Elastic Container Services)와 Google의 GKE와 같은 다른 클라우드 서비스 대비 아직 기능 개발이 부족한 상태이다. 
    - 기본적인 모니터링 연계를 위한 기능역시 개발이 진행중
    - AWS 클라우드 서비스의 높은 시장 점유율을 바탕으로 EC2 인스턴스에 직접 Kubernetes를 수동으로 설치하여 사용하는 비중이 높은것으로 보인다
  
2-2.테스트 결과 상세

3.어플리케이션 테스트 결과
3-1.테스트 결과 요약
    - Kubernetes 기본 기능을 활용하는 부분이 많음.
    - 기존 AWS 서비스와의 결합해서 사용할 수 있는 부분이 아직은 부족하다.
    - 네트워크, 보안 부분은 AWS VPC, Subnet 등 네트워크 관련 서비스를 사용하여 효과적으로 관리가 가능.
    - 이 외에 어플리케이션 관리에 필요한 서비스들(Cloudwatch, Autoscaling 등)은 로드맵에 따라 진행이 되어 EKS와의 결합도가 올라간다면 AWS에서 EKS를 보다 효과적으로 사용할 수 있으며, 사용 편의성 또한 올라갈 것이라고 기대된다.

3-2.테스트 결과 상세

4.도입/구축 시 고려사항
4-1.서비스 리전
    - EKS는 현재 시점('18년 10월)에 3개 리전에서 서비스가 되고 있으며, 아직 한국에서는 서비스가 되고 있지 않다.
      (미국 동부(버지니아 북구),미국 서부(오레곤),EU(아일랜드))

4-2.비용 산정
  1)Amazon ECR(Elastic Container Registry)
    - Amazon Elastic Container Registry는 Repository에 저장한 데이터 용량과 인터넷으로 전송한 데이터 양에 대한 네트웍 사용량 비용으로 구성됨. 
    - Amazon ECR 프리 티어에는 매월 500MB의 스토리지 사용료까지는 무료이며 500MB 이상 사용량만 과금되며 스토리지 사용료는 GB당 0.10$/USD 입니다.
  
  2)EKS(Elastic Container Service for Kubernetes)
    - GKE/AKS와 달리 EKS는 클러스터 노드에 대한 비용이 청구되며 시간당 0.20$/USD가 과금 됩니다.
    - Worker 노드의 사용료는 GKE/AKS와 마찬가지로 EC2 인스턴스 사용료 및 EBS 스토리지 사용료로 과금 됩니다.  

4-3.사용자 Role 설정에 대한 관리 방안
  1) EKS Master node의 Role
     - EKS Master node의 Role은 EKS Cluster 생성단계에서 생성할 수 있으며, 
     - 기본적으로 AmazonEKSServicePolicy, AmazonEKSClusterPolicy 두 개의 Policy가 할당된다
     
  2) EKS Worker node의 Role
     - Worker Node의 Role은 eksctl을 통해 EKS Cluster 생성 시 자동 생성되며, 
     - Worker Node의 Role은 내부에서 생성되는 Pod에 상속되며 추가로 필요한 Policy는 추가로 IAM Policy를 통해 Attach 할 수 있다.
     - EKS Worker node에게 할당되는 Role은 AmazonEKSWorkerNodePolicy이다. 
     
4-4.EKS와 AWS CloudWatch와의 연계 
    - AWS CloudWatch 서비스는 아마존 내 각종 리소스에 대한 모니터링 및 알림, 로깅 기능 사용을 제공하며, 해당 지표를 이용해 SNS, Lambda 등의 서비스와도 손쉽게 연동이 가능하다.
    - 하지만, 아직 CloudWatch에서 EKS에 대한 지원은 되지 않는다. (로드맵 3개월 내)
    - 추후 EKF와 Cloudwatch가 연계되면 Master node에 대한 통합 로깅, 컨테이너 모니터링, SNS를 연계한 알람 서비스 등을 사용할 수 있을 것이다.
    - 현재는 Cloudwatch를 통해 확인할 수 있는 EKS 정보는 EC2에 생성된느 Worker Node에 대한 모니터링, 로깅만 가능하다. 
    - Node별 Container 배포 현황 등의 컨테이너 레벨의 모니터링이 필요할 때에는 Kubernetes native dashboard, 또는 Prometheus, Grafana를 구성하여 확인해야한다. 
    - SNS 연동이 필요한 때에는 Pod, Node 레벨의 로그를 FluentD를 통해 S3, Cloudwatch로 받은 후 해당 이벤트를 트리거 하여 사용할 수 있다.
    
    ========================================================================================================================================
    
    [GKE 기반 개발 가이드]
1.Container Registry 사용방법
1-1.Container Registry 소개
    - Container Registry는 Docker 컨테이너 이미지를 저장, 관리할 수 있는 비공개 Docker Registry이다.
    - GKE 사용 시 Google Cloud에서 제공하는 Container Registry를 사용할 수 있으며, 
    - Global Cloud가 제공하는 관리형 서비스로 고가용성이 보장된다. 
    - Container Registry는 별도 Registry 생성 없이, Docker image 저장소로 gcr.io/[PROJECT-ID] 를 사용하면 된다

1-2.사용 방법 
    - Dockerfile을 이용해 build 후 해당 이미지를 Container Registry에 등록한다. 
    - 이미지 작업 전 gcloud 인증 작업을 진행한다. 
    - 이후 작업 내용은 Docker-Registry를 사용하는 방법과 동일하다.

1-3.가격 정책
    - 컨테이너 이미지가 저장되는 Cloud Storage(Object Storage)와 네트워크 송신에 대해서만 비용을 청구한다

2.CI/CD 구성방법
2-1.CI/ CD 배포 구성
2-2.Jenkins 활용하기
    - Helm 이용한 설치
    - Marketplace 이용한 설치
2-3.Spinnaker 활용하기
    - Spinnaker 소개
    - Spinnaker 사용방법
 
3.MSA 구성을 위한 Istio 활용
  - 마이크로 서비스 아키텍쳐가 발전하면서 서비스의 크기와 복잡성이 올라감에 따라 Application의 구조, 네트워크 등의 관리가 어려워지고 있다. 
  - Google은 오픈소스인 Istio를 이용해 이런 부분을 효과적으로 관리하고 있다. 
  - Istio는 Service Discovery, Load balancing, Failure recovery, Monitoring 등을 Application 코드 단이 아닌 Proxy 서버 (인프라 서버)에서 구현이 가능하게 해준다. 

3-1.소개
    - Istio는 Evnoy Proxy를 Control 해주는 서비스이다.  
    - Envoy란 L7 Layer의 Proxy로 Service Discovery, Health Check 기능을 수행해준다
    - Service A가 Service B를 호출할 경우를 예로 설명해보자.
      1)Proxy A는 Pilot을 통해 Configuration을 읽어오며, Service 간의 SSL 통신을 위해 Istio Auth를 통해 인증서 정보도 가져온다. 호출준비가 완료된 상태이다. 
      2)Service A가 Service B를 호출할 경우 직접 호출이 아닌 Proxy A가 Proxy B를 호출한다. Pilot을 통해 Configuration 정보를 가져와 Proxy A는 Proxy B의 정보를 이미 알고 있다.  Service Discovery 기능을 지원한다.
      3)Proxy B가 응답을 받으면 Mixer에게 Policy를 확인 후 호출을 승인하여 Service B에게 전달한다.
      4)Service B에게 Proxy B가 결과를 Return 받으면 Mixer에 모니터링 정보를 남긴 후 Proxy A에게 Response를 전달한다. 
      5)Proxy A는 Response를 Service A에게 전달하며 응답에 대해 모니터링 정보를 남긴다

3-2.설치
    - Google Lab을 참고하여 Istio 설치를 진행할 수 있다.  (관련 Lab : https://google.qwiklabs.com/focuses/616 )

3-3.테스트
    - Istio 설치 후 내부에 테스트를 진행할 수 있는 sample Application이 존재한다. 
    - Application은 아래와 같이 구성되며 /productpage로 요청을 받으면 reviews-v1, reviews-v2, reviews-v3의 deployment를 가진 service에 연결되어 자동으로 부하분산이 된다. Istio 설정을 통해 버전에 따라 Traffic을 조정 (Traffic Splitting)할 수 있으며, HTTP Header를 이용해 조정 (Traffic Steering)도 가능하다

4.로그 분석 및 모니터링 방법
4-1.로그분석
    - Kubernetes 기능을 이용하여 컨테이너 내부에 있는 실시간 로그를 확인할 수 있다. 

4-2.Google Cloud 콘솔을 활용한 모니터링
    - Google Cloud 콘솔에서는 Container의 구성요소별 각각의 항목에 대해 개별 모니터링이 가능하도록 제공해준다.
     
    1)Pod별 모니터링
      - Kubernetes Engine > 클러스터 > 클러스터 선택 > 노트 Tab 선택 > Node 선택 > Pod 선택을 하면 해당 Pod의 CPU, 메모리, 디스크사용량에 대해 모니터링 할 수 있으며 해당 pod에서 발생한 Event도 확인이 가능하다
    2)Node별 모니터링
      - Kubernetes Engine > 클러스터 > 클러스터 선택 > 노트 Tab 선택 > Node 선택을 하면  해당 Node의 CPU, 메모리, 디스크사용량에 대해 모니터링 할 수 있으며 해당 node에서 발생한 Event도 확인이 가능하다. 
    3)Deployment 모니터링
      - Kubernetes Engine > 작업부하> 배포 선택을 하면 해당 Deployment의 CPU, 메모리, 디스크 사용량에 대해 모니터링 할 수 있으며, 해당 Deployment 내에서 발생한 Event도 확인이 가능하다. 
    4)Service 모니터링
      - Kubernetes Engine > 서비스 > 서비스 선택을 하면  해당 서비스의 CPU, 메모리, 디스크사용량에 대해 모니터링 할 수 있으며, 해당 Service에서 발생한 Event도 확인이 가능하다
     
4-3.Stackdriver 활용한 모니터링
    - Google Cloud에서는 Stackdriver를 이용해 각 모니터링이 가능하도록 지원한다.
    
    1)리소스 모니터링
      - Google Cloud 내 Stackdriver > 모니터링 항목을 클릭하면 프로젝트내 리소스 별 모니터링을 할 수 있다.
    2)로그 확인
      - Google Cloud 내 Stackdriver > 로그기록 > 로그에 접속하면 리소스별 로그를 확인할 수 있다. 
      - 또한, 상단의 ▶ 버튼을 클릭하면 스트리밍으로 실시간 로그도 확인이 가능하다.
    3)실시간 Debugging 방법
      - App Engine을 이용 시 Stackdriver의 Debugging 기능을 이용하여 구동 중인 Application의 실시간 Debugging이 가능하다. 해당 기능은 GKE 기능은 아니지만, Google Cloud에서 제공하는 기능 중 유용한 기능 중 하나로 소개한다.  
      - App Engine > Version > Tools  > Debug를 통해 접속할 수 있다. 
    4)모니터링 데이터 보관 주기
      - Stackdrive 내 모니터링 데이터 보관 주기는 최대 30일이다. 30일 이상의 로그 데이터 수집이 필요한 경우 Cloud Storage, BigQuery로 옮겨서 관리하는 것을 권고한다

[GKE 아키텍처 가이드]
1.테스트 아키텍처
1-1.GKE 개요
    - GKE(Google Kubernetes Engine)는 GCP(Google Cloud Platform) 기반에 컨테이너식 애플리케이션 배포를 위한 관리형 환경입니다. GKE 클러스터는 Kubernetes 명령 및 Resource를 사용하여 응용 프로그램을 배포 및 관리 하고 자동 배포를 위한 배포 정책 설정과 어플리케이션 상태 모니터링 서비스를 제공합니다. 

1-2.아키텍처 구성
    - 어플리케이션 라이프사이클 관점에서 구성하는 방법을 정의한다.
    
      1) 형상관리
      2) CI/CD
      3) 컨테이너 레지스트리
      4) 런타임 어플리케이
      5) 데이터베이스
      6) 로깅/모니터링
       
1-3.GKE와 GAE 비교
    - 컨테이너를 실행할 수 있는 서비스를 비교하여 아키텍트가 각자의 환경에 적합한 서비스를 활용할 수 있도록 한다.
    
    1)GKE(Google Kubernets Engine)
      - Kubernetes를 기반으로 하는 컨테이너식 어플리케이션을 관리형 환경이다. 
      - 개발자 생산성, 리소스 효율성, 자동화된 작업, 오픈소스 유연성에 혁신을 가져와 제품 출시 시간을 단축해준다. 
      - OS 위에 컨테이너가 구동되는 형태로 애플리케이션과 서비스를 손쉽게 배포, 업데이트, 관리할 수 있다.
      - 컨테이너 복제,  모니터링, 복구를 사용하여 서비스 가용성을 높여 사용자에게 원활한 환경을 제공할 수 있다. 
      - 리소스를 최적화 하여 사용할 수 있으며, 수요에 맞게 확장/축소가 유용하다. 
      - GKE를 사용하는 개발자는 서비스를 컨테이너로 구성하고 구동하는 부분만 하면 된다.
    2)GAE(Google App Engine)
      - 완전 관리형 서버리스 어플리케이션 플랫폼이다. 
      - 기본 인프라를 걱정하지 않고, 어플리케이션을 원할하게 확장할 수 있다. 
      - 개발자는 서버 관리와 구성 배포를 고민하지 않고 어플리케이션을 개발하고 사용한 리소스에 대해 비용만 지불하면 된다. 
      - 자바, PHP, Node.js, Python, C#, .Net, Ruby, Go 등 일반적인 개발 언어 및 개발자 도구를 지원하여 개발자들의 높은 생산성과 민첩성에 도움이 된다. 
      - 어플리케이션 확장, 축소, 패치와 같은 인프라 작업은 Google에서 관리한다.
      
1-4.Kubernetes와 GKE 비교
    - 오픈소스 Kubernetes 대비 Google Cloud가 제공하는 차별적인 기능에 대해 소개한다.
    
    1) 액세스 관리 : Google 계정 및 역할 권한으로 클러스터의 액세스 권한을 관리함
    2) 네트워킹 : Google Cloud VPN를 이용해 컨테이너 클러스터에 하이브리드 네트워킹을 구성이 가능함
    3) 보안 및 규정 :  Google 보안팀이 Kubernetes Engine을 지원하며 HIPAA 및 PCI DSS 3.1 규정을 모두 준수
    4) 통합 로깅 및 모니터링 : Stackdriver Logging과 Stackdriver Monitoring을 사용 설정하면 애플리케이션 실행 상태를 손쉽게 확인이 가능함
    5) 자동 업그레이드 : Kubernetes의 최신 출시 버전으로 클러스터를 자동으로 최신 상태로 유지함
    6) 자동 복구 : 자동 복구를 사용 설정하면 노드 상태 확인에 실패할 경우 Kubernetes Engine이 실패한 노드의 복구 프로세스를 시작함
    7) 완전 관리형 서비스 : Google SRE가 Kubernetes Engine을 완전하게 관리하므로 클러스터의 가용성이 보장되고 최신 상태로 유지됨
    8) Private Container Registry : Google Container Registry와 통합하면 손쉽게 Private Docker 이미지를 저장하고 액세스가 가능함
    9) 신속한 빌드 : Google Container Builder를 사용하면 인증을 설정할 필요 없이 Kubernetes Engine에서 안정적으로 컨테이너를 배포가 가능함
    10) 사용 편의성 : 콘솔 화면 내에 터미널 접속 기능이 있어, 별도의 CLI 설치 작업 없이 손쉽게 사용이 가능함 

2. 플랫폼 테스트 결과
2-1.테스트 결과 요약
    - Google Cloud Platform에서 서비스중인 GKE(Google Kubernetes Engine)의 플랫폼 기능을 사용해보고 테스트 결과를 설명합니다. 
    - Google GKE는 다른 퍼블릭 클라우드 및 Kubernetes 기반 PaaS 플랫폼과 비교하여 가장 완성도가 높음.
    - 오랜 운영 노하우를 바탕으로 필요한 옵션 기능을 플랫폼 기본 기능에 포함시켜 놓았다.  
    - 특히 Kubernetes auto upgrade와 auto repair와 같은 자동화 기능이 우수.
    - Stackdriver와 같은 모니터링 서비스와의 연계 기능도 잘 되어 있다.
    
2-2.테스트 결과 상세

3. 어플리케이션 테스트 결과
3-1.테스트 결과 요약
    - 컨테이너 빌드/배포/관리를 위한 유용한 도구를 제공.
    - GCP와 결합하여 보안 설정 및 모니터링 부분도 효과적으로 관리가 가능
    - Container를 처음 사용하는 사용자도 쉽게 접근할 수 있도록 별도의 Client 환경 구성 없이 CLI를 사용할 수 있는 Cloud shell과 같은 유용한 도구를 제공.
    - Stackdriver를 이용해 모니터링, Tracing, 로깅, Debugging 등을 효과적으로 관리할 수 있다. 
    - Container Registry를 구성해서 별도의 Private Registry를 설치 하지 않아도 사용이 가능하다. 
    - Istio, Spinnaker 등 Kubernetes 진영의 MSA 도구와 유기적으로 연동되었다.

4. 도입구축 시 고려사항
4-1.서비스 리전
    - Google은 현재 시점('18년 10월)에 한국에 데이터선터를 가지고 있지 않으며, 한국과 가장 가까운 데이터센터는 일본 도쿄이다. 
    - (아시아에는 대만, 싱가폴, 일본에 데이터 센터가 있다.)
    - '19년 한국에 데이터센터를 설립할 예정이며 GKE 서비스가 될 예정이다.

4-2.비용 산정
    1)Container Registry
      - Container Registry 비용은 저장한 이미지 개수가 아니라 이미지 저장에 사용되는 Cloud Storage 저장소 비용과 데이터 전송에 사용한 Network 송신량 비용으로 구성됩니다. 
      - Container Registry 저장소에 처음으로 이미지를 Push 하면 시스템에서 모든 이미지를 저장하기 위한 Cloud Bucket을 만듭니다. 
      - 이때 사용되는 Cloud Bucket은 Multi-Regional 스토리지 입니다.

    2)GKE
      - GKE(Google Kubernetes Engine)은 GCE(Google Compute Engine)을 클러스터 노드로 사용합니다. 
      - 따라서 GCP 노드 대수에 비례하여 비용이 산정되며 클러스터 노드 생성 시점 부터 삭제될 때까지 청구되며 최소 사용 기준은 1분이며 그 이후로는 초단위로 사용시간 만큼 과금 됩니다. 
      아래의 링크를 참조하여 구성하고자 하는 옵션을 선택하며 월비용을 예상해 볼 수 있습니다.

    3)Stackdriver
      - Stackdriver를 사용하면 자원 사용량과 지출관리를 할 수 있으며 
      - stackdriver 사용가격은 사용한 만큼 지불하는 방식 입니다. 
      - 용도별 월별 무료 사용 할당량이 있으며 무료 사용량 이상 사용한 부분에 대해서 사용료를 지불하게 됩니다. 
      - Cloud Bill Reports 페이지와 Logging, Monitoring, Trace 콘솔에서 현재 사용량을 확인 할 수 있으며 이를 기준으로 향후 사용량을 예상하여 Stackdriver 예상 청구금액을 산정 할 수 있습니다.
        + Stackdriver 가격 & 로그 보관 기간
          - 관리 활동 감사 로그 : 400일(프리미엄 등급)400일(기본 등급)
          - 데이터 액세스 감사 로그 : 30일(프리미엄 등급)7일(기본 등급)
          - 감사 로그 외의 로그 : 30일(프리미엄 등급)7일(기본 등급)

    4)Google Cloud IAM 계정 관리 방안
      - Google Cloud 내에서는 IAM을 이용하여 조직이 필요로 하는 보안 정책을 수립하고 정책에 따라 자동으로 사용자의 계정과 권한을 관리할 수 있다.  
      - IAM을 이용해 효율적으로 클라우드 운영 조직을 관리 하기 위해서 부서나 서비스 단위로 독립적인 프로젝트 및 빌링 관리가 필요.
      - 실제 회사의 조직을 클라우드 운영 조직에 맵핑할 수 있어야 한다
      - 조직은 프로젝트의 상위개념으로 IAM 에서 설정해 줄 수 있다. 
      - 프로젝트는 Resource의 관리 단위로 빌링의 단위이다. 
      - GKE를 구성할 때 Quota를 설정해 준다면 이 값은 프로젝트 단위로 관리가 된다.  
      - 실제 프로젝트를 진행할 경우에 사용자의 계정은 LDAP 를 연결하여 생성할 수 있다. 
      - 참고로 GKE의 Service Account는 Google API를 사용할 수 있는 계정을 의미하는 것으로 최대 100개까지 생성이 가능한다

    5)Cloud shell 소개
      - GKE에서는 콘솔화면을 통해 사용자가 바로 이용이 가능한 가상 머신 인스턴스를 제공한다.  
      - Google Cloud 콘솔 화면에 접속하면 Cloud shell을 활성화하면 가상머신을 이용이 가능하다. 
      - Cloud shell에는 다음과 같은 도구들이 설치되어 있다.
        + Linux 셸 인터프리터	: bash, sh
        + Linux 유틸리티	: 표준 Debian 시스템 유틸리티
        + Google SDK 및 도구 : Google App Engine SDK, gcloud 명령줄 도구를 포함한 Google Cloud SDK, Cloud Storage용 gsutil
        + 텍스트 편집기 : Emacs, Vim, Nano
        + 빌드 및 패키지 도구 : Gradle, Make, Maven, Bazel, npm, nvm, pip
        + 소스 제어 도구 : Git, Mercurial
        + 추가 도구 : Kubectl, Docker, iPython, MySQL 클라이언트, gRPC 컴파일러, TensorFlow
        + 화면 우측 상단의 아이콘을 클릭하면 Cloud shell에 접속이 가능하다

=====================================================================================================================================================

[AKS 기반 개발 가이드]

1.Container Registry 사용방법
1-1.Container Registry (ACR) 소개
    - ACR은 Azure에서 제공하는 Container Registry이다. 
    - AKS 사용 시 Azure에서 제공하는 Container Registry를 사용할 수 있음
    - Storage Account 기반.  
    - ACR은 99.9%의 SLA를 제공.
    - Premium SKU의 경우 GEO Replication옵션을 제공(Geo Replication은 실제 DR을 염두한 데이터 복제 옵션이다. )
    - Container Registry는 CLI 또는 Marketplace에서 생성하여 사용이 가능하며 생성된 레지스트리의 상세 정보는 리소스 관리 화면에서 확인이 가능하다. 

1-2.사용 방법
    - Marketplace에서 Container Registry를 검색하여 생성이 가능하다. 
    - 이름과 Region, 가격정책(SKU)을 설정하면 간단하게 설치가 된다. 
    - 또는 CLI를 이용해서 사용이 가능하다. 

1-3.가격 정책
    - 컨테이너 이미지가 저장되는 Storage 사이즈, 사용 기간, Web Hook 횟수, Geo Replication 여부에 따라 
    - SKU를 Basic, Standard, Premium으로 나누고 이것에 따라 가격이 책정된다.  

2.CI/CD 구성방법
2-1.Azure DevOps 활용하기 
    - Azure는 DevOps 솔루션을 제공하여, 클라우드 내에서 개발 간소화, 가속화, 지속적인 배포를 지원하여 안정성 있는 개발, 운영을 지원해준다. 
    - Azure DevOps를 활용하여 위와 같은 아키텍처로 CI/ CD를 구성할 수 있다. 
	    1)Source Control에 소스코드를 Push 한다. 
	    2)코드가 Git에 업데이트 되면 CI 빌드 파이프라인이 Trigger 된다.
	    3)Azure Container Registry로 생성 및 저장된 Container Image(Docker Image)에 앱 코드가 Package된다.
	    4)빌드가 성공적으로 완료되면 CD 파이프라인이 Trigger 된다. 
	    5)성공적으로 Release가 되면 컨테이너 이미지를 Helm Chart를 사용하여 AKS에 배포한다. 
	    6)Git을 통해 소스가 업데이트 될 때마다 반복된다. 

2-2.Azure DevOps 사용하기
    - Azure DevOps 사이트에 접속하여 Project를 생성한다. 생성 후 Git과 연동하여 저장소의 소스를 가져온다.
	    1)빌드 파이프라인을 생성한다. 
	    2)Empty Job을 선택하여 새로운 빌드 Job을 생성한다. 
	    3)파이프라인의 이름을 지정해주고 Agent Pool을 선택해준다. 
	    4)첫번째 Job으로 Azure CLI Task를 추가하여 넣는다. 
	    5)Azure CLI에서 사용할 버전, Azure subscription 정보를 넣고 Inline Script를 추가한다. 
	    6)스크립트 안에 ACR Name은 각 프로젝트에서 사용하는 ACR 정보로 변경해준다.  Inline Script의 내용은 아래에서 참고할 수 있다. 
	    7)두번째 Job으로 Publish Build Artifacts를 추가한다. 
	    8)Save&queue 버튼을 클릭하여 설정한 Pipeline을 실행한다. 각 단계별 진행 사항과 로그를 확인할 수 있다. 
	    9)빌드가 완료되면 Release 파이프라인을 설정한다. 
	    10)New Pipeline 선택하여 Stage를 선택하여 새로운 Build Artifact를 추가한다. 
	    11)Build Pipeline 구성과 마찬가지로 Job이름과 Agent Pool을 선택한다. 
	    12)추가 Task로 Helm tool Installer와 Package and deploy Helm charts를 추가한다. 이때 Helm tool Installer를 먼저 선택해야한다. 
	    13)Helm upgrade Job에 Azure subscription 정보와 AKS Cluster 정보를 추가한다. 
	    14)Pipeline을 저장한 후 수행한다. 
	    15)Release가 완료되면 해당 Pipeline을 Deploy 할 수 있다. 

2-3.Jenkins 활용하기
    - Azure Console에서 Marketplace에서 Jenkins를 검색하면 사용할 수 있다.
    - Jenkins 기본 설정 구성 시 SSH Public Key를 생성하여 사용한다. SSH Public Key는 ssh-key gen을 이용하여 생성할 수 있는다. 
    - Jenkins에서 사용할 VM, Network 등 인프라 설정을 위한 추가 정보를 입력한다. 
    - 클라우드 에이전트 사용 여부를 체크해준다. 
	    1)ACI가 Azure Container Instance를 참조하고, VM이 가상 머신을 참조하는 에이전트에 대한 기본 템플릿을 지정해준다.  
	    2)클라우드 에이전트를 사용하지 않도록 설정 하려면 No를 지정한다. 
    - 생성이 완료되면 DNS 이름을 확인하여 접속이 가능하다. 
    - 접속 시 Port Forwarding 방식으로 로컬에서 접속을 하여 Jenkins의 초기 암호를 획득 후 해당 암호를 이용하여 Jenkins를 사용한다. 

3.로그 분석 및 모니터링 방법
3-1.Application Insight를 활용한 모니터링
    - Azure에서 제공하는 Application Insight를 이용하여 리소스 및 어플리케이션 모니터링에 유용하게 사용할 수 있다. 

3-2.모니터링을 위한 Insight 설정 
    - 인사이트로 모니터링 및 로그 확인을 위해서 모니터링 할 리소스의 Insight 진단 설정을 하면 데이터 수집이 가능하다. 
    - 진단 설정을 할 Log의 종류와 수집 방법 (Log, Metric)을 선택하면 로그 분석 작업이 가능하다. 

3-3.클러스터 모니터링
    - AKS 리소스 선택 > 모니터링 > 인사이트 메뉴 내에서 클러스트 탭을 확인하면 해당 클러스터의 CPU 사용률, Memory 사용률, 노드 개수, 활성 Pod 개수에 대한 정보를 확인할 수 있다. 

3-4.노트, 컨트롤러, 컨테이너 모니터링 
    - AKS 리소스 선택 > 모니터링 > 인사이트 메뉴 내에서 노드, 컨트롤러, 컨테이너 탭을 각각 선택하면 각 요소들에 대한 정보를 모니터링 할 수 있다. 
    - Kubernetes 개체를 구성하기 위해 정의한 레이블을 포함하여 각 선택 항목의 속성을 확인할 수 있다. 

3-5.Application Map 확인하기
    - 여러 구성 요소로 구성된 어플리케이션의 경우 Application Insight를 이용해 HTTP 종속성을 확인할 수 가 있다. 
    - 확인을 위해서 리소스는 Application Insights의 리소스이며 어플리케이션 내부에 Application Insights SDK가 설치되어 있어야한다. 
    - 여러 구성 요소로 구성되어진 어플리케이션의 경우 각각의 구성 요소의 정보를 확인하고 구성요소의 성능 및 API별 분석을 하는데 유용하게 사용할 수 있다. 
    - 자세한 내용은 Triage Distributed Applications 설명을 참조한다. 

3-6.Log Analytics를 활용한 로그 분석 
    - 컨테이너 로그를 Log Analytics 기능을 이용하여 분석 가능 하다. 
    - Query를 사용하여 검색이 가능하며, Cluster ID별, Container별, Compute별 등 필터 기능 사용도 가능하다. 

3-7.실시간 로그 분석
    - Pod에 인입되는 실시간 로그 분석을 위한 서비스가 현재 Preview 단계로 준비되고 있다.  
    - 서비스가 완성되면 인사이트 메뉴 내에서 Pod를 선택하여 라이브 로그 보기를 이용하여 실시간 로그를 확인할 수 있다.

3-8. 데이터 보관 주기
    - Azure 내에 로그 보관 기간은 90일이다. 
    - 그 이상의 장기 보관이 필요할 경우 로그를 추출하여 별도로 관리 해야한다. 

[AKS 아키텍처 가이드]
1.테스트 아키텍처
1-1.AKS 개요
    - AKS(Azure Kubernetes Service)는 Azure Cloud Platform 기반에 컨테이너식 애플리케이션 배포를 위한 관리형 환경입니다. 
    - AKS 클러스터는 Kubernetes 명령 및 Resource를 사용하여 
      1) 응용 프로그램을 배포 및 관리
      2) 자동 배포를 위한 배포 정책 설정
      3) 어플리케이션 상태 모니터링 서비스를 제공.

1-2.아키텍처 구성
    - 형상관리
    - CI/CD
    - 컨테이너 레지스트리
    - 런타임 어플리케이션
    - 데이터베이스
    - 로깅/모니터링 등을 어플리케이션 라이프사이클 관점에서 구성하는 방법을 정의한다. 

1-3.AKS 기반의 Microservice CI/CD 아키텍처
    - Container 서비스를 통해 매우 손쉽게 응용 프로그램을 지속적으로 빌드 및 배포할 수 있습니다. 
    - AKS(Azure Kubernetes Service)에서 Kubernetes를 사용하여 
      1) 해당 컨테이너의 배포를 오케스트레이션하는 방식으로 컨테이너를 복제 가능하고 관리 가능한 클러스터를 구성 할 수 있습니다.

1-4.AKS vs. ACI vs. Container Services
    - 다양한 종류의 Container Service를 제공. 
    - 최종 목적은 컨테이너 서비스에 Microservice 기반 애플리케이션을 개발/배포하기 위한 편리한 환경을 제공하는것
    - 비용/용도/개발환경에 따라 다양한 기능과 기술지원이 필요하기 때문에 사용자가 목적에 맞게 선택 할 수 있도록 다양한 컨테이너 환경을 지원.

    1)AKS(Azure Kubernetes Services)
      - 완벽한 관리형 Kubernetes 환경 제공
      - Container 오케스트레이션에 대한 전문 지식 없이 컨테이너화된 응용 프로그램을 빠르고 쉽게 배포하고 관리할 수 있는 클러스터 구성 환경을 제공.
      - 응용 프로그램을 오프라인으로 변경하지 않고 온라인으로 클러스터 추가 리소스를 프로비전하고, 업그레이드하고, 크기 조정하여 진행 중인 작업 및 유지 관리를 간편하게 할 수 있습니다. 
      - 사용자 요구사항에 맞도록 VPC Network을 구성하거나 다른 Azure 서비스와 연계가능한 Container 서비스 환경을 만들 수 있습니다.  

    2)ACI(Azure Container Instances)
      - 클라우드 응용 프로그램을 패키지, 배포 및 관리하기 위한 기본 환경을 제공.
      - 컨테이너 서비스를 제공하는 가상 머신을 직접 관리하지 않고 Azure에서 컨테이너를 실행하는 가장 빠르고 간단한 방법을 제공.
      - 간단한 응용 프로그램, 작업 자동화 및 빌드 작업 등 간단하게 격리된 컨테이너 실행 환경이 필요한 경우에 적합한 솔루션.
      - 여러 컨테이너 간 서비스 검색, 자동 크기 조정 및 조정된 응용 프로그램 업그레이드를 포함하여 전체 컨테이너 오케스트레이션이 필요한 환경
        => AKS(Azure Kubernetes Service)가 좀더 적합.

    3)Container Services
      - Azure Portal, Azure 명령줄 도구 및 Azure API의 기능이 포함된 SLA 기반 Azure 서비스.
      - 몇가지 구성 옵션을 통해 표준 컨테이너 오케스트레이션 도구(DC/OS, Docker Swarm, Kubernetes)를 선택하고 실행하는 클러스터를 신속하게 구현하고 관리할 수 있음.
      - ACS Engine은 고급 사용자가 모든 수준의 클러스터 구성을 사용자가 변경하여 사용할 있는 오픈 소스 프로젝트입니다. 인프라 및 소프트웨어 양쪽의 구성을 변경하는 기능이 있기 때문에 ACS Engine용 SLA는 Azure에서 제공되지 않으며 운영자 담당자가 직접 모든 서비스를 관리하는 환경에 사용할 수 있습니다. 
      - 현재 Container Service는 서비스 종료 예정입니다.

    4)Service Fabric Clusters
      - 손쉽게 패키지하고 배포하며 확장 가능하고 안정성이 뛰어난 마이크로 서비스 및 컨테이너를 관리하도록 배포된 시스템 플랫폼.
      - 클라우드 네이티브 응용 프로그램 개발 및 인프라 관리를 간편하게 제공.
      - 개발자와 관리자가 복잡한 인프라 문제를 피하고 업무 수행에 필수적인 까다로운 어플리케이션을 확장 가능하고 안정적인 서비스를 제공
      - 컨테이너에서 실행되는 엔터프라이즈급 Level1 클라우드 규모의 응용 프로그램을 빌드 및 관리하기 위한 차세대 플랫폼 서비스.

    5)App Services
      - Windows와 Linux에서 사용할 수 있는 Azure Web App을 통해 개발자는 인프라 관리에 대해 걱정할 필요 없이 다양한 언어로 작성되고 다수의 서비스와 통합된 엔터프라이즈급 웹 응용 프로그램을 손쉽게 배포하고 확장할 수 있습니다. 
      - Web App for Containers 을 통해 개발자는 고유한 Docker 형식의 컨테이너 이미지를 가져와서 Azure에서 대규모로 쉽게 배포하고 실행할 수 있습니다. 
      - zure Functions는 기존 Azure App Service 플랫폼을 확장하는, 서버를 사용하지 않는 이벤트 구동 환경입니다. 매우 작은 리소스를 사용하는 어플리케이션에 적합하며 크기를 조정할 수 있으므로 사용한 리소스에 대해서만 비용을 지불합니다. 
      - Azure API Apps를 사용하여 다양한 언어로 작성된 API를 쉽게 빌드, 호스팅 서비스를하는데 이용할 수 있습니다.

1-5.AKS와 Kubernetes 비교
    - 액세스 관리 : Azure 포털의 Identity 카테로그의 서비스를 활요앟여 계정 및 역할 권한으로 클러스터의 액세스 권한을 관리함
    - 네트워킹 : AKS Advanced 네트웍 옵션을 이용해 컨테이너 클러스터에 하이브리드 네트워킹을 구성이 가능함
    - 보안 및 규정 :  AKS 보안팀이 Kubernetes Engine을 지원하며 HIPAA 및 PCI DSS 3.1 규정을 모두 준수
    - 통합 로깅 및 모니터링 : Monitoring 카테고리의 Logs, Metrics, Insights(Preview) 기능을 사용 설정하면 애플리케이션 실행 상태를 손쉽게 확인이 가능함
    - 자동 업그레이드 : Kubernetes의 최신 출시 버전으로 클러스터를 자동으로 최신 상태로 유지 할수 있으며 N-4 버전까지 지원함.
    - 완전 관리형 서비스 : AKS Kubernetes Engine을 완전하게 관리하므로 클러스터의 가용성이 보장되고 최신 상태로 유지됨
    - Private Container Registry : Azure Container Registry와 통합하면 손쉽게 Private Docker 이미지를 저장하고 액세스가 가능함
    - 신속한 빌드 : DevOps 서비스를 사용하여 Kubernetes Engine에서 안정적으로 컨테이너를 배포 및 CI/CD 구성이 가능함.
    - 사용 편의성 : 콘솔 화면 내에 터미널 접속 기능이 있어, 별도의 CLI 설치 작업 없이 손쉽게 사용이 가능함 

2.플랫폼테스트 결과
2-1.테스트 결과 요약
    - Microsoft Azure에서 서비스중인 AKS(Azure Kubernetes Service) 플랫폼 서비스는 전체적으로 Google GKE 플랫폼와 유사하지만 세부적인 기능 옵션 및 자동화 관련 기능에서 일부 부족한 부분이 있는것으로 보인다. 
    - 모니터링 통합 기능 및 서비스들의 카테고리별 재그룹핑등은 사용자가 직관적으로 사용하기에 편리한 구성으로 보인다.  
    - 그리고 다른 퍼블릭 클라우드 서비스에서 사용하는 Region 및 AZ(Availability Zone) 개념이 일부 차이가 있으므로 플랫폼 가용성 확보를 위한 아키텍처 설계시 검토가 필요할 것으로 보인다. 

3.어플리케이션 테스트 결과
3-1.테스트 결과 요약
    - AKS는 전체적으로 Kubernetes를 효과적으로 관리할 수 있는 다양한 기능을 제공해주고 있다. 
    - 개발자용 클러스터인 Azure Dev Spaces를 제공하고 VS Code를 사용하는 개발자가 로컬환경을 쉽게 구성할 수 있게 해주며,  
    - Insight, Log Analytics 등 로그 분석 및 리소스 모니터링 기능을 효과적으로 사용할 수 있다. 
    - 전체적으로 서비스를 보면, 기능 및 콘솔에서 제공해주는 Cloud Shell 등 GCP와 유사한 부분이 많으며, 
    - 다양한 서비스 기능들이 현재 추가가 되고 있는 상태이다. 
    - 한 예로 인사이트경우 Preview 단계에서 테스트를 진행하는 동안 정식 서비스로 Release가 되며 기능이 추가된 것을 확인할 수 있었다. 
    - 하지만, 콘솔을 이용할 경우 서비스 속도와 안정성 등에서는 아직 은 부족하게 느껴진다. 

4.도입/구축 시 고려사항
4-1.서비스 리전
    - Azure는 현재 시점('18년 12월)에 전세계 54개 Region과 140국가에 서비스 중
    - 한국에는  중부리전과 남부리전이 서비스 중이다. 
    - 한국 리전에는 AKS 서비스는 제공되고 있지 않다. 
    - Azure에서 사용하는 Global Infra는 다른 퍼블릭 클라우드 서비스에서는 사용하는 Region, AZ(Availability Zones) 용어의 개념이 약간 차이가 있다.

    1)Region
      - 정해진 latency 내에 배치된 데이터 센터의 집합으로 Low-latency 네트웍으로 연결되어 있습니다.
    2)Geographies
      - 일반적으로 두개 이상의 리전을 포함하는 별개의 Market 입니다.  
      - 동일한 규정 및 데이터 레지던시를 보장.
      - 특정 데이터 레지던시 및 규정 요구 사항이 있는 고객은 Geographies를 통해 Region에 발생하는 장애에 대비하여 데이터와 응용 프로그램의 가용성을 보장할 수 있음.
    3)Availability Zones 
      - AZ는 Azure Region내에 물리적으로 분위된 위치를 말합니다. 
      - 각  AZ 영역은 독립된 전원, 냉각 및 네트워킹을 갖춘 하나 이상의 데이터 센터로 구성 됩니다.  

4-2.AKS(Azure Kubernetes Service) 제공 Region
    - 모든 Azure 서비스에는 리소스와 기능에 대한 제약 사항이 있습니다. AKS 서비스의 기본 리소스 제한과 서비스 가능한 지역을 설명합니다.
    - AKS 기본 서비스 및 제약 사항
      1) Azure CLI 배포
      2) Azure CLI 또는 Resource Manager 템플릿을 사용하여 POD를 AKS 클러스터에 배포할 때 이 값은 네트웍 설정에 따라 최대 배포할 수 있는 최대값이 달라질 수 있습니다.

4.3.비용 산정
    1)Container Registry
      - ACR(Azure Container Registry)은 다중 서비스 계층(즉, SKU)에서 사용 가능합니다. 
      - SKU는 예측 가능한 가격 책정과 Azure에서 개인 Docker 레지스트리의 용량 및 사용량 패턴에 맞추기 위한 여러 옵션을 제공합니다.
      - AKS(Azure Kubernetes Service)
    2)AKS(Azure Kubernetes Service)
      - Kubernetes의 배포, 관리 및 작업을 완전히 관리되는 Kubernetes 컨테이너 오케스트레이터 서비스로 간소화하는 무료 컨테이너 서비스입니다. 
      - 사용된 가상 머신과 연결된 저장소 및 네트워킹 리소스에 대한 요금만 결제한다면 AKS가 출시 제품 중 가장 효율적이고 비용 효과적인 Container Service입니다. 
      - Kubernetes Master node는 무료이며 Worker Node 사용료만 과금 됩니다.

4-4.AKS 클러스터 네트워크 옵션
    - AKS 클러스터 생성 시 네트워크 옵션은 Basic/Advanced 2가지 방식으로 선택하여 구성이 가능.  
    - Advanced 방식은 GCP의 VPC-native(alias IP) 기능과 유사 합니다.
      + Basic 네트워킹 - AKS 클러스터가 배포될 때 네트워크 리소스가 만들어지고 구성됩니다.
      + Advanced  네트워킹 - AKS 클러스터가 기존 가상 네트워크 리소스 및 구성에 연결됩니다.

  1) Basic 네트워킹
     - Basic 네트워킹 옵션은 AKS 클러스터 생성시 기본 구성입니다. 
     - Azure 플랫폼은 클러스터와 Pod의 네트워크 구성을 관리합니다. 
     - Basic 네트워킹은 사용자가 직접 가상 네트워크 구성이 필요하지 않은 배포에 적합합니다. 
     - Basic 네트워킹에서는 AKS 클러스터에 할당된 서브넷 이름 또는 IP 주소 범위와 같은 네트워크 구성을 선택 할 수 없습니다.  
     - Basic 네트워킹에 대해 구성된 AKS 클러스터의 노드에는 kubenet Kubernetes 플러그인이 구성됩니다.
       + Azure Load Balancer를 통해 외부 또는 내부로 Kubernetes 서비스를 제공합니다.
       + Pod는 공용 인터넷의 리소스에 액세스할 수 있습니다.

  2) Advanced 네트워킹
     - Advanced 네트워킹은 구성한 Azure VPC에 Pod를 직접 연결 합니다.  
     - VPC 네트워크는 다른 Azure 리소스에 대한 자동 연결 및 다양한 기능을 제공합니다.  
     - Advanced 네트워킹은 기존 서브넷  연결 사용과 같은 특정 가상 네트워크 구성이 필요한 배포에 적합합니다.  
     - Advanced 네트워킹을 사용하면 이러한 서브넷 이름과 IP 주소 범위를 지정할 수 있으며 구성된 AKS 클러스터의 노드에는 Azure CNI(컨테이너 네트워킹 인터페이스) Kubernetes 플러그인이 구성됩니다.
       + AKS 클러스터를 기존 Azure 가상 네트워크에 배포하거나 클러스터에 대한 새 가상 네트워크와 서브넷을 만듭니다.
       + 클러스터의 모든 Pod에 VPC 네트워크의 IP 주소가 할당됩니다. Pod에서 클러스터의 다른 Pod 및 VPC 네트워크의 다른 노드와 직접 통신할 수 있습니다.
       + Pod는 ER(ExpressRoute)와 S2S(사이트 간) VPN 연결을 통한 On-premise 네트워크를 포함하여 피어링된 VPC 네트워크의 다른 서비스에 연결할 수 있습니다.
       + 서비스 엔드포인트를 사용하도록 설정된 서브넷의 Pod는 Azure 서비스(예: Azure Storage 및 SQL DB)에 안전하게 연결될 수 있습니다

  3) Advanced 네트웍킹 고려사항
     - 필요한 IP 주소 수에는 업그레이드 및 Scale 작업에 대해 검토되어야 합니다. 
     - 고정 노드 수만 지원하는 IP 주소 범위를 설정할 경우 클러스터의 업그레이드나 노드 확장 계획을 반영해야 합니다.
       + AKS 클러스터를 업그레이드할 경우 새 노드가 클러스터에 배포됩니다. 
       + 서비스 및 워크로드가 새 노드에서 실행되기 시작하고 기존 노드가 클러스터에서 제거됩니다. 
       + 이 업그레이드 배포 프로세스를 위해서 최소 하나 이상의 추가 IP 주소 블록을 사용할 수 있어야 합니다. 
       + AKS 클러스터를 확장할 경우 새 노드가 클러스터에 배포됩니다. 
       + 서비스 및 워크로드가 새 노드에서 실행되기 시작하며 IP 주소 범위에서는 클러스터가 지원할 수 있는 노드 및 Pod 수가 변경될 여유 IP 주소를 가지고 있어야 합니다. 
       + 업그레이드 작업에 대한 추가 노드 하나도 포함되어야 합니다.

4-5.Cloud shell 소개
    - Google Cloud에서와 마찬가지로  시스템 관리 콘솔화면을 통해 브라우저 기반의  CLI 환경을 제공하는 Cloud Shell을 사용 할 수 있습니다.  
    - Google Cloud Shell은 30GB 정도의 용량에 cloud shell에 대한 root 권한까지 부여함에따라 기본적으로 설치되어 있는 유틸리티외에 사용자가 필요한 유틸리티의 추가 설치가 가능하고 무료서비스로 제공됩니다. 
    - Azure Cloud Shell의 경우 cloud shell을 사용하기 위해서는 반드시 디스크를 연결해야 하며 디스크 비용은 유료
    - cloud shell의 일반 유저 권한만 부여하여 제공되는 기본 유틸리티 이외에 추가로 사용자가 필요한 유틸리티를 설치 할 수 없습니다.

4-6.Resource Group  
    - Azure에는 Resource Group을 사용할 수 있다. 
    - Resource group이란 Azure에 포함된 리소스를 관리하는 그룹이다. 
    - 사용자는 Resource Group을 이용하여 사용자 조직에 가장 적합한 리소스를 할당하고 관리할 수 있다. 
    - 일반적으로 함께 배포, 업데이트 하는 리소스들을 한 그룹에 추가하여 동일한 수명주기를 가질 수 있도록 관리한다. 
    - 리소스그룹 내에 Tag 기능을 사용하여 부서, 환경 등의 값을 설정하여 해당 리소스 그룹을 관리할 수 있다. 
    - 부서별로 리소스 그룹을 분리하여 관리하거나, 개발-Stage-QA-Production 으로 환경을 분리하여 리소스를 관리할 때 Tag 기능을 유용하게 사용할 수 있다. 
    - 리소스 그룹은 다른 구독, 다른 리소스 그룹으로 이동이 가능하며, 
    - 리소스별 Lock을 설정하여 실수로 리소스가 삭제, 수정되는 것을 예방할 수 있다. 
    - 그룹별로 전체 리소스그룹을 일괄 삭제할 수 있다. 
    - 사용자별 역할을 할당할 때, 리소스 그룹, 리소스, 구독에 따라 역할 부여가 가능하므로 특정 사용자가 특정 Resource Group에만 접속할 수 있도록 권한을 관리 할 수 있다. 
